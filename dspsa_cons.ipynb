{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decentralized SPSA Simulation\n",
    "\n",
    "This notebook implements and evaluates a decentralized gradient-free optimization method (DSPSA) under various types of drift, noise, and communication topologies. The goal is to simulate challenging scenarios that resemble real-world multi-agent systems with noisy feedback and dynamic optima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import levy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMUM DRIFT SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriftScenario:\n",
    "    def __init__(self, mode, dim, total_steps, jump_step=None, step_size=0.05):\n",
    "        self.mode = mode\n",
    "        self.dim = dim\n",
    "        self.total_steps = total_steps\n",
    "        self.jump_step = jump_step or total_steps // 2\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def get_theta_star(self, t):\n",
    "        if self.mode == 'linear':\n",
    "            # Linear drift over time\n",
    "            return np.ones(self.dim) * self.step_size * t\n",
    "        elif self.mode == 'jump':\n",
    "            # Sudden jump at a given step\n",
    "            if t < self.jump_step:\n",
    "                return np.zeros(self.dim)\n",
    "            else:\n",
    "                return np.ones(self.dim) * 3.0\n",
    "        else:\n",
    "            raise ValueError(\"Unknown drift mode\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOISE GENERATOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseGenerator:\n",
    "    def __init__(self, noise_type, size, **kwargs):\n",
    "        self.noise_type = noise_type\n",
    "        self.size = size\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def sample(self):\n",
    "        if self.noise_type == 'gaussian':\n",
    "            # Gaussian noise with zero mean\n",
    "            return np.random.normal(loc=0, scale=self.kwargs.get('sigma', 0.1), size=self.size)\n",
    "        elif self.noise_type == 'pareto':\n",
    "            # Zero-centered Pareto noise\n",
    "            p = np.random.pareto(self.kwargs.get('shape', 2), size=self.size)\n",
    "            return (p - p.mean()) * self.kwargs.get('scale', 1)\n",
    "        elif self.noise_type == 'levy':\n",
    "            # Lévy noise\n",
    "            return levy.rvs(size=self.size)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown noise type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AGENT GRAPH GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ring_graph(n):\n",
    "    # Ring topology: each agent connected to its two neighbors\n",
    "    adj = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        adj[i, (i+1)%n] = 1\n",
    "        adj[i, (i-1)%n] = 1\n",
    "    return adj\n",
    "\n",
    "def make_random_k_neighbors(n, k=3):\n",
    "    # Random-k graph: each agent connected to k random other agents\n",
    "    adj = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        k_eff = min(k, n-1)\n",
    "        neighbors = np.random.choice([j for j in range(n) if j != i], k_eff, replace=False)\n",
    "        for j in neighbors:\n",
    "            adj[i, j] = 1\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LOSS FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent_function(c_i, rho=1.5):\n",
    "    # Agent-specific function with ℓ_rho norm\n",
    "    def f(x):\n",
    "        diff = x - c_i\n",
    "        value = np.sum(np.abs(diff) ** rho)\n",
    "        grad = np.sign(diff) * (np.abs(diff) ** (rho - 1))\n",
    "        return value, grad\n",
    "    return f\n",
    "\n",
    "class LossFunction:\n",
    "    def __init__(self, rho, noise_generator):\n",
    "        self.rho = rho\n",
    "        self.noise_generator = noise_generator\n",
    "\n",
    "    def value(self, x, theta_star):\n",
    "        # x: (n, d), theta_star: (d,)\n",
    "        # Add noise to ℓ_rho norm loss\n",
    "        noise = self.noise_generator.sample()\n",
    "        diff = np.abs(x - theta_star)\n",
    "        return np.sum(diff ** self.rho, axis=1) + noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC AGENT CLASS & SIMULATION LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, idx, x_init):\n",
    "        self.idx = idx\n",
    "        self.x = np.copy(x_init)\n",
    "        self.history = [np.copy(self.x)]\n",
    "\n",
    "    def update(self, new_x):\n",
    "        # Update agent's internal state\n",
    "        self.x = np.copy(new_x)\n",
    "        self.history.append(np.copy(self.x))\n",
    "\n",
    "\n",
    "class SimulationLogger:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "\n",
    "    def log(self, t, agent_states, theta_star, loss_values):\n",
    "        # Store simulation snapshot for timestep t\n",
    "        record = {\n",
    "            't': t,\n",
    "            'agent_states': [np.copy(x) for x in agent_states],\n",
    "            'theta_star': np.copy(theta_star),\n",
    "            'loss_values': np.copy(loss_values)\n",
    "        }\n",
    "        self.logs.append(record)\n",
    "\n",
    "    def get_agent_trajectories(self, idx):\n",
    "        # Retrieve trajectory of agent i over time\n",
    "        return [step['agent_states'][idx] for step in self.logs]\n",
    "\n",
    "    def get_theta_star_trajectory(self):\n",
    "        # Retrieve trajectory of optimum θ*(t)\n",
    "        return [step['theta_star'] for step in self.logs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN SIMULATION ORGANIZER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    def __init__(self, num_agents, dim, drift_scenario, noise_generator, loss_func, adjacency, method, steps=200):\n",
    "        self.num_agents = num_agents\n",
    "        self.dim = dim\n",
    "        self.drift = drift_scenario\n",
    "        self.noise_gen = noise_generator\n",
    "        self.loss_func = loss_func\n",
    "        self.adjacency = adjacency\n",
    "        self.steps = steps\n",
    "        self.method = method\n",
    "        self.agents = [Agent(i, np.random.uniform(-5, 5, dim)) for i in range(num_agents)]\n",
    "        self.logger = SimulationLogger()\n",
    "\n",
    "    def run(self):\n",
    "        for t in range(self.steps):\n",
    "            theta_star = self.drift.get_theta_star(t)\n",
    "            X = np.stack([agent.x for agent in self.agents], axis=0)\n",
    "            loss_vals = self.loss_func.value(X, theta_star)\n",
    "            self.logger.log(t, [agent.x for agent in self.agents], theta_star, loss_vals)\n",
    "            new_states = self.method.step([agent.x for agent in self.agents], theta_star, t, self.adjacency, self.loss_func)\n",
    "            for agent, new_x in zip(self.agents, new_states):\n",
    "                agent.update(new_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DSPSA-CONSENSUS METHOD ====\n",
    "class DSPSAConsensus:\n",
    "    def __init__(self, alpha=0.1, gamma=0.2, beta=0.1, spsa_seed=None):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.rng = np.random.default_rng(spsa_seed)\n",
    "\n",
    "    def step(self, states, theta_star, t, adjacency, loss_func):\n",
    "        n, d = np.shape(states)\n",
    "        states = np.array(states)\n",
    "        grad_est = []\n",
    "\n",
    "        # SPSA gradient estimation for each agent\n",
    "        for i in range(n):\n",
    "            delta = self.rng.choice([-1, 1], size=d)\n",
    "            x_plus = states[i] + self.beta * delta\n",
    "            x_minus = states[i] - self.beta * delta\n",
    "            f_plus = loss_func.value(x_plus[None, :], theta_star)[0]\n",
    "            f_minus = loss_func.value(x_minus[None, :], theta_star)[0]\n",
    "            grad_i = (f_plus - f_minus) / (2 * self.beta) * delta\n",
    "            grad_est.append(grad_i)\n",
    "\n",
    "        grad_est = np.stack(grad_est)\n",
    "        new_states = []\n",
    "\n",
    "        # Consensus + descent step\n",
    "        for i in range(n):\n",
    "            consensus = np.zeros(d)\n",
    "            for j in range(n):\n",
    "                if adjacency[i, j]:\n",
    "                    consensus += (states[j] - states[i])\n",
    "            new_x = states[i] - self.alpha * grad_est[i] + self.gamma * consensus\n",
    "            new_states.append(new_x)\n",
    "\n",
    "        return new_states\n",
    "    \n",
    "# ==== DISTRIBUTED SUBGRADIENT METHOD ====\n",
    "class DistributedSubgradient:\n",
    "    def __init__(self, alpha=0.1, gamma=0.2, rho=1.5):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.rho = rho\n",
    "\n",
    "    def subgrad(self, x, theta_star):\n",
    "        # Subgradient of the ℓ_rho norm\n",
    "        diff = x - theta_star\n",
    "        grad = np.sign(diff) * (np.abs(diff) ** (self.rho - 1))\n",
    "        return grad\n",
    "\n",
    "    def step(self, states, theta_star, t, adjacency, loss_func):\n",
    "        n, d = np.shape(states)\n",
    "        states = np.array(states)\n",
    "        grad_est = []\n",
    "\n",
    "        # Compute local subgradients\n",
    "        for i in range(n):\n",
    "            grad_i = self.subgrad(states[i], theta_star)\n",
    "            grad_est.append(grad_i)\n",
    "\n",
    "        grad_est = np.stack(grad_est)\n",
    "        new_states = []\n",
    "\n",
    "        # Consensus + gradient step\n",
    "        for i in range(n):\n",
    "            consensus = np.zeros(d)\n",
    "            for j in range(n):\n",
    "                if adjacency[i, j]:\n",
    "                    consensus += (states[j] - states[i])\n",
    "            new_x = states[i] - self.alpha * grad_est[i] + self.gamma * consensus\n",
    "            new_states.append(new_x)\n",
    "\n",
    "        return new_states\n",
    "\n",
    "# ==== DISTRIBUTED KIEFER–WOLFOWITZ METHOD ====\n",
    "class DistributedKieferWolfowitz:\n",
    "    def __init__(self, alpha=0.1, gamma=0.2, h=0.05):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.h = h\n",
    "\n",
    "    def grad_estimate(self, x, theta_star, loss_func):\n",
    "        # Finite-difference gradient estimation\n",
    "        d = x.size\n",
    "        grad = np.zeros(d)\n",
    "        for k in range(d):\n",
    "            e_k = np.zeros(d)\n",
    "            e_k[k] = 1\n",
    "            f_plus = loss_func.value((x + self.h * e_k)[None, :], theta_star)[0]\n",
    "            f_minus = loss_func.value((x - self.h * e_k)[None, :], theta_star)[0]\n",
    "            grad[k] = (f_plus - f_minus) / (2 * self.h)\n",
    "        return grad\n",
    "\n",
    "    def step(self, states, theta_star, t, adjacency, loss_func):\n",
    "        n, d = np.shape(states)\n",
    "        states = np.array(states)\n",
    "        grad_est = []\n",
    "\n",
    "        # Estimate gradient for each agent\n",
    "        for i in range(n):\n",
    "            grad_i = self.grad_estimate(states[i], theta_star, loss_func)\n",
    "            grad_est.append(grad_i)\n",
    "\n",
    "        grad_est = np.stack(grad_est)\n",
    "        new_states = []\n",
    "\n",
    "        # Consensus + gradient update\n",
    "        for i in range(n):\n",
    "            consensus = np.zeros(d)\n",
    "            for j in range(n):\n",
    "                if adjacency[i, j]:\n",
    "                    consensus += (states[j] - states[i])\n",
    "            new_x = states[i] - self.alpha * grad_est[i] + self.gamma * consensus\n",
    "            new_states.append(new_x)\n",
    "\n",
    "        return new_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GRAPH GENERATOR WRAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(graph_type, n):\n",
    "    if graph_type == 'ring':\n",
    "        return make_ring_graph(n)\n",
    "    elif graph_type == 'random_k':\n",
    "        return make_random_k_neighbors(n, k=3)\n",
    "    elif graph_type == 'random':\n",
    "        return make_random_graph(n, p=0.3)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown graph type {graph_type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCENARIO PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULL SIMULATION EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_all_scenarios(steps=200, random_seed=42, num_runs=20):\n",
    "    results = []\n",
    "    scenario_id = 0\n",
    "    for n_agents in agent_counts:\n",
    "        for dim in dimensions:\n",
    "            for graph_type in graph_types:\n",
    "                for rho in rhos:\n",
    "                    for noise_type in noise_types:\n",
    "                        for drift_type in drift_types:\n",
    "                            for method_name, method_class in methods_dict.items():\n",
    "                                scenario_id += 1\n",
    "                                for run in range(num_runs):\n",
    "                                    np.random.seed(random_seed + run)  # ensure different seed per run\n",
    "\n",
    "                                    # Drift setup\n",
    "                                    drift = DriftScenario(drift_type, dim, steps)\n",
    "\n",
    "                                    # Noise generator\n",
    "                                    noise_params = {'sigma': 0.2} if noise_type == 'gaussian' else {'shape': 2, 'scale': 1}\n",
    "                                    noise_gen = NoiseGenerator(noise_type, size=n_agents, **noise_params)\n",
    "\n",
    "                                    # Loss function\n",
    "                                    loss_func = LossFunction(rho, noise_gen)\n",
    "\n",
    "                                    # Communication graph\n",
    "                                    adjacency = get_graph(graph_type, n_agents)\n",
    "\n",
    "                                    # Method instantiation\n",
    "                                    if method_name == 'evolution_strategy':\n",
    "                                        method = method_class(n_arms=5, gamma=0.2)\n",
    "                                    elif method_name == 'dspsa_consensus':\n",
    "                                        method = method_class(alpha=0.1, gamma=0.2, beta=0.1)\n",
    "                                    elif method_name == 'consensus_only':\n",
    "                                        method = method_class(gamma=0.9)\n",
    "                                    elif method_name == 'subgradient':\n",
    "                                        method = method_class(alpha=0.1, gamma=0.2, rho=rho)\n",
    "                                    elif method_name == 'kiefer_wolfowitz':\n",
    "                                        method = method_class(alpha=0.1, gamma=0.2, h=0.05)\n",
    "                                    else:\n",
    "                                        raise ValueError(\"Unsupported method\")\n",
    "\n",
    "                                    # Run simulation\n",
    "                                    sim = Simulator(n_agents, dim, drift, noise_gen, loss_func, adjacency, method, steps)\n",
    "                                    sim.run()\n",
    "\n",
    "                                    # Extract logs\n",
    "                                    for record in sim.logger.logs:\n",
    "                                        t = record['t']\n",
    "                                        theta_star = record['theta_star']\n",
    "                                        for agent_idx, (x, loss) in enumerate(zip(record['agent_states'], record['loss_values'])):\n",
    "                                            if method_name == 'evolution_strategy':\n",
    "                                                chosen_arm = int(x[0])\n",
    "                                                true_arm = int(np.clip(theta_star[0], 0, method.n_arms - 1))\n",
    "                                                error = abs(chosen_arm - true_arm)\n",
    "                                            else:\n",
    "                                                error = np.linalg.norm(x - theta_star)\n",
    "                                            results.append({\n",
    "                                                'scenario_id': scenario_id,\n",
    "                                                'run': run,\n",
    "                                                'num_agents': n_agents,\n",
    "                                                'dimension': dim,\n",
    "                                                'graph': graph_type,\n",
    "                                                'rho': rho,\n",
    "                                                'noise': noise_type,\n",
    "                                                'drift': drift_type,\n",
    "                                                'method': method_name,\n",
    "                                                'iteration': t,\n",
    "                                                'agent': agent_idx,\n",
    "                                                'x': x.copy(),\n",
    "                                                'theta_star': theta_star.copy(),\n",
    "                                                'loss': loss,\n",
    "                                                'error': error,\n",
    "                                            })\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==== RUN IF EXECUTED AS SCRIPT ====\n",
    "if __name__ == \"__main__\":\n",
    "    df = run_all_scenarios(steps=200, random_seed=42, num_runs=20)\n",
    "    print(df.head())\n",
    "    df.to_csv('scenarios_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
